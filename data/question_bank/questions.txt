1. What should intermediaries ensure about the use of AI models or algorithms on their platforms as per the IT Rules?

2. How must intermediaries and platforms address bias or discrimination in their AI systems?

3. What must be done before making under-tested or unreliable AI models available to users in India?

4. How should users be informed about the potential unreliability of output generated by AI systems?

5. What mechanisms should be in place to notify users about the risks of AI-generated outputs?

7. What must intermediaries label or embed in synthetic information to ensure traceability?

8. How should intermediaries ensure the identification of users making changes to synthetic content?

9. What legal risks do intermediaries face for non-compliance with the IT Act 2000 and IT Rules?

10. What immediate actions must intermediaries take to comply with the updated guidelines?